{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b499ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c20bd4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    # Define paths\n",
    "    file_path = 'G:/My Drive/github/msc-ai-cw/dataset/processed/cinnamon_quality_dataset.csv'\n",
    "    \n",
    "    # Load the dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f\"Initial dataset shape: {data.shape}\")\n",
    "    \n",
    "    # Handle null values\n",
    "    print(\"Handling missing values...\") \n",
    "    missing_before = data.isnull().sum().sum()\n",
    "    print(f\"Missing values before cleaning: {missing_before}\")\n",
    "    \n",
    "    # Fill numerical NaNs with median\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if 'Sample_ID' in num_cols:\n",
    "        num_cols.remove('Sample_ID')\n",
    "    \n",
    "    data[num_cols] = data[num_cols].fillna(data[num_cols].median())\n",
    "    \n",
    "    # Drop rows with missing target\n",
    "    data = data.dropna(subset=['Quality_Label'])\n",
    "    \n",
    "    missing_after = data.isnull().sum().sum()\n",
    "    print(f\"Missing values after cleaning: {missing_after}\")\n",
    "    print(f\"Dataset shape after handling missing values: {data.shape}\")\n",
    "    \n",
    "\n",
    "    # Remove noise/outliers using Z-score\n",
    "    print(\"Removing outliers using Z-score method...\")\n",
    "\n",
    "    # Calculate Z-scores for numerical columns\n",
    "    z_scores = np.abs((data[num_cols] - data[num_cols].mean()) / data[num_cols].std())\n",
    "    \n",
    "    # Remove rows where any feature has Z-score > 3\n",
    "    outlier_mask = (z_scores < 3).all(axis=1)\n",
    "    outliers_removed = len(data) - outlier_mask.sum()\n",
    "    \n",
    "    data = data[outlier_mask]\n",
    "    \n",
    "    print(f\"Outliers removed: {outliers_removed}\")\n",
    "    print(f\"Final dataset shape: {data.shape}\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = data.drop(columns=[\"Sample_ID\", \"Quality_Label\"])\n",
    "    y = data[\"Quality_Label\"]\n",
    "    \n",
    "    # Check class distribution\n",
    "    print(f\"\\nClass distribution:\")\n",
    "    print(y.value_counts().sort_index())\n",
    "    \n",
    "    # Encode target labels\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7000b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "    print(\"Training Logistic Regression...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    log_reg = LogisticRegression(\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        max_iter=10000,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    log_reg.fit(X_train, y_train)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    return log_reg, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c39a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train):\n",
    "    print(\"Training Random Forest...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    return rf, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9c37f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X_train, y_train):\n",
    "    print(\"Training SVM with Grid Search...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    param_grid = {\n",
    "        'C': [1, 10],\n",
    "        'gamma': ['scale', 0.1],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        SVC(probability=True, random_state=42),\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        verbose=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    return best_svm, training_time, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bd6c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name, training_time, le):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{model_name} Results\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Predictions\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    prediction_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "    print(f\"Prediction Time: {prediction_time:.4f} seconds\")\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "    \n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'training_time': training_time,\n",
    "        'prediction_time': prediction_time,\n",
    "        'y_pred': y_pred\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e79f2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_summary(results):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"MODELS COMPARISON SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_df = pd.DataFrame([\n",
    "        {\n",
    "            'Model': result['model_name'],\n",
    "            'Accuracy (%)': f\"{result['accuracy']*100:.2f}\",\n",
    "            'Training Time (s)': f\"{result['training_time']:.2f}\",\n",
    "            'Prediction Time (s)': f\"{result['prediction_time']:.4f}\"\n",
    "        }\n",
    "        for result in results\n",
    "    ])\n",
    "    \n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Find best model\n",
    "    best_model = max(results, key=lambda x: x['accuracy'])\n",
    "    print(f\"\\nBest Model: {best_model['model_name']} with {best_model['accuracy']*100:.2f}% accuracy\")\n",
    "    \n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "827540b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Classical ML Algorithms Comparison for Cinnamon Quality Classification\n",
      "================================================================================\n",
      "Loading and preprocessing data...\n",
      "Loading dataset...\n",
      "Initial dataset shape: (8692, 14)\n",
      "Handling missing values...\n",
      "Missing values before cleaning: 70\n",
      "Missing values after cleaning: 0\n",
      "Dataset shape after handling missing values: (8692, 14)\n",
      "Removing outliers using Z-score method...\n",
      "Outliers removed: 0\n",
      "Final dataset shape: (8692, 14)\n",
      "\n",
      "Class distribution:\n",
      "Quality_Label\n",
      "High      2944\n",
      "Low       2859\n",
      "Medium    2889\n",
      "Name: count, dtype: int64\n",
      "Dataset Info:\n",
      "- Training samples: 6953\n",
      "- Test samples: 1739\n",
      "- Features: 12\n",
      "- Classes: ['High' 'Low' 'Medium']\n",
      "Training Logistic Regression...\n",
      "\n",
      "==================================================\n",
      "Logistic Regression Results\n",
      "==================================================\n",
      "Training Time: 0.02 seconds\n",
      "Prediction Time: 0.0000 seconds\n",
      "Accuracy: 82.35%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.90      0.85      0.87       589\n",
      "         Low       0.85      0.88      0.86       572\n",
      "      Medium       0.73      0.74      0.74       578\n",
      "\n",
      "    accuracy                           0.82      1739\n",
      "   macro avg       0.82      0.82      0.82      1739\n",
      "weighted avg       0.83      0.82      0.82      1739\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[498   0  91]\n",
      " [  0 504  68]\n",
      " [ 56  92 430]]\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Random Forest Results\n",
      "==================================================\n",
      "Training Time: 1.13 seconds\n",
      "Prediction Time: 0.0724 seconds\n",
      "Accuracy: 89.88%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.94      0.91      0.92       589\n",
      "         Low       0.92      0.93      0.93       572\n",
      "      Medium       0.84      0.86      0.85       578\n",
      "\n",
      "    accuracy                           0.90      1739\n",
      "   macro avg       0.90      0.90      0.90      1739\n",
      "weighted avg       0.90      0.90      0.90      1739\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[534   0  55]\n",
      " [  0 534  38]\n",
      " [ 37  46 495]]\n",
      "Training SVM with Grid Search...\n",
      "Best SVM Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "==================================================\n",
      "Support Vector Machine Results\n",
      "==================================================\n",
      "Training Time: 18.40 seconds\n",
      "Prediction Time: 0.3267 seconds\n",
      "Accuracy: 91.20%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.95      0.93      0.94       589\n",
      "         Low       0.92      0.94      0.93       572\n",
      "      Medium       0.87      0.87      0.87       578\n",
      "\n",
      "    accuracy                           0.91      1739\n",
      "   macro avg       0.91      0.91      0.91      1739\n",
      "weighted avg       0.91      0.91      0.91      1739\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[548   0  41]\n",
      " [  0 537  35]\n",
      " [ 30  47 501]]\n",
      "\n",
      "======================================================================\n",
      "MODELS COMPARISON SUMMARY\n",
      "======================================================================\n",
      "                 Model Accuracy (%) Training Time (s) Prediction Time (s)\n",
      "   Logistic Regression        82.35              0.02              0.0000\n",
      "         Random Forest        89.88              1.13              0.0724\n",
      "Support Vector Machine        91.20             18.40              0.3267\n",
      "\n",
      "Best Model: Support Vector Machine with 91.20% accuracy\n"
     ]
    }
   ],
   "source": [
    "def main():    \n",
    "    print(\"Starting Classical ML Algorithms Comparison for Cinnamon Quality Classification\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    X_train, X_test, y_train, y_test, le = load_and_preprocess_data()\n",
    "    \n",
    "    print(f\"Dataset Info:\")\n",
    "    print(f\"- Training samples: {X_train.shape[0]}\")\n",
    "    print(f\"- Test samples: {X_test.shape[0]}\")\n",
    "    print(f\"- Features: {X_train.shape[1]}\")\n",
    "    print(f\"- Classes: {le.classes_}\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Train and evaluate Logistic Regression\n",
    "    log_reg, log_reg_time = train_logistic_regression(X_train, y_train)\n",
    "    log_reg_results = evaluate_model(log_reg, X_test, y_test, \"Logistic Regression\", log_reg_time, le)\n",
    "    results.append(log_reg_results)\n",
    "    \n",
    "    # Train and evaluate Random Forest\n",
    "    rf, rf_time = train_random_forest(X_train, y_train)\n",
    "    rf_results = evaluate_model(rf, X_test, y_test, \"Random Forest\", rf_time, le)\n",
    "    results.append(rf_results)\n",
    "    \n",
    "    # Train and evaluate SVM\n",
    "    svm, svm_time, best_params = train_svm(X_train, y_train)\n",
    "    print(f\"Best SVM Parameters: {best_params}\")\n",
    "    svm_results = evaluate_model(svm, X_test, y_test, \"Support Vector Machine\", svm_time, le)\n",
    "    results.append(svm_results)\n",
    "    \n",
    "    # Final comparison\n",
    "    comparison_summary = compare_models_summary(results)    \n",
    "    return results, comparison_summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results, summary = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
